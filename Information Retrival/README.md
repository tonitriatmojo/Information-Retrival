# Information-Rettrival-Models
This project involved comparing two different information retrieval ranking algorithms against the BM25 model. The data used was various collections of articels with a query that was only relevant to a subset of articles within the queries collection. The two other models chosen were the TF-IDF ranking and Likelihood model. The comparison of all three models was done through comparing recall, precision, F1. While F1 scores indicated that the TF-IDF and Likelihood models preformed better their recall was much higher then BM25 and their increase in precision was likely due to just returning more documents as relevant. The models struggled with a few queries where the query had terms like Sport Utility Vehicle that was abbreviated to SUV in the article text. Other Queries the models struggled with were when terms like U.K. were present, as these terms were typically stemmed by the stemming and stopword methods used. While there was no noted signifigant difference between Likelihood and TF-IDF it should be noted that Liklihood model had a mazimum recall, which demonstrates that its percision was not through intitive design but rather the result of returing all articles as relevant. 

The data that was used for this assignment was given under strict guidance that it only be used for this asssignment so it will not be avaliable within the GitHub.

A jupyternotebook is provided with the outputs from the code.
